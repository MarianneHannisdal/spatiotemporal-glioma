{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 SynthSR, SynthSeg, Synthetic White matter lobes using KNN\n",
    "\n",
    "\n",
    "Arvid Lundervold/Marianne Hannisdal\n",
    "\n",
    "Last updated: **2025-03-13**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel: segment_glioma (Python 3.9.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 13 18:53:09 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.06             Driver Version: 535.183.06   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX 3500 Ada Gene...    On  | 00000000:01:00.0 Off |                  Off |\n",
      "| N/A   43C    P0              N/A /  90W |      8MiB / 12282MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1569      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '18'\n",
    "home = os.path.expanduser('~')\n",
    "import os.path as op\n",
    "import glob\n",
    "import shutil\n",
    "import subprocess as subp\n",
    "import pathlib\n",
    "import platform\n",
    "import shutil\n",
    "import IPython\n",
    "from datetime import date\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib\n",
    "from nibabel.viewers import OrthoSlicer3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import pickle\n",
    "import pydicom\n",
    "from pydicom import dcmread\n",
    "# import imageio\n",
    "import imageio.v2 as imageio\n",
    "\n",
    "%matplotlib inline\n",
    "home = os.path.expanduser('~')            # To make a path to local home directory\n",
    "                       \n",
    "warnings.filterwarnings('ignore')  # To ignore warnings \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 18:53:34.232007: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-13 18:53:34.239458: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-13 18:53:34.247991: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-13 18:53:34.250529: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-13 18:53:34.257238: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-13 18:53:34.659561: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.17.0\n",
      "No GPU found. Running on CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741888416.438768   54061 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-13 18:53:36.456299: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Check if GPU is available\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print(\"GPU available:\", gpu_devices)\n",
    "else:\n",
    "    print(\"No GPU found. Running on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "platform: Linux-6.8.0-45-generic-x86_64-with-glibc2.39\n",
      "python version: 3.11.9\n",
      "pydicom version: 2.4.4\n",
      "nibabel version: 5.2.1\n",
      "pandas version: 2.2.2\n",
      "numpy version: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "print(f'platform: {platform.platform()}')\n",
    "print(f'python version: {platform.python_version()}')\n",
    "print(f'pydicom version: {pydicom.__version__}')\n",
    "print(f'nibabel version: {nib.__version__}')\n",
    "print(f'pandas version: {pd.__version__}')\n",
    "print(f'numpy version: {np.__version__}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "verbose = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining directories:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRJ_DIR = f'{home}/prj/glioma_recurrence/glioma_recurrence'\n",
    "SITE = '10'\n",
    "\n",
    "REGISTERED_dir = f'{PRJ_DIR}/data/{SITE}/registered_1'\n",
    "SYNTHSEG_dir = f'{REGISTERED_dir}/synthseg'\n",
    "SYNTH_SR_dir = f'{REGISTERED_dir}/synth_sr'\n",
    "FS741_dir = f'{PRJ_DIR}/data/{SITE}/FS-741'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define all the channels and get a list of all (test) subjects in the directory:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 examinations:\n",
      "[\n",
      "'10_036',\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#all_chns = ['T1', 'CT1', 'T2', 'FLAIR']\n",
    "all_chns = ['CT1']\n",
    "\n",
    "all_dirs = sorted(glob.glob(f'{REGISTERED_dir}/{SITE}_*'))    # exams from local recordings\n",
    "subjs = [ os.path.basename(d) for d in all_dirs]\n",
    "n = len(subjs)\n",
    "\n",
    "print(f'{n} examinations:')\n",
    "print('[')\n",
    "for i, sub in enumerate(subjs):\n",
    "      print(f\"'{sub}',\")\n",
    "print(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/marianne/prj/glioma_recurrence/glioma_recurrence/data/10/registered_1\u001b[0m\n",
      "└── \u001b[01;34m10_036\u001b[0m\n",
      "\n",
      "1 directory, 0 files\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute tree command on the easyreg subdirecory \n",
    "print(os.popen(f'{TREE} {REGISTERED_dir}').read())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Freesurfer's `mri_synthSR` and `mri_synthseg` on the coregistred T1 (CT1) images in the `REGISTERED` directory\n",
    "\n",
    "See also https://surfer.nmr.mgh.harvard.edu/fswiki/WMH-SynthSeg\n",
    "\n",
    "`mri_WMHsynthseg --i <input> --o <output> [--csv_vols <CSV file>] [--device <device>]  [--threads <threads>] [--crop] [--save_lesion_probabilities]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/freesurfer/bin/mri_synthseg\n"
     ]
    }
   ],
   "source": [
    "!which mri_synthseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: EXAMS_LIST_STR='10_036'\n"
     ]
    }
   ],
   "source": [
    "# Get the sorted list of directories (exams) inside EASYREG_dir\n",
    "exams_list = sorted([x for x in next(os.walk(REGISTERED_dir))[1]])\n",
    "\n",
    "# Convert the list to a string with each element inside single quotes and separated by a space\n",
    "exams_list_str = \" \".join([f\"'{x}'\" for x in exams_list])\n",
    "\n",
    "# Set it as an environment variable so Bash can access it\n",
    "%env EXAMS_LIST_STR=$exams_list_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'10_036'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Access the environment variable created in Python\n",
    "list=($EXAMS_LIST_STR)\n",
    "\n",
    "# Removing commas and storing in a new array\n",
    "list_new=()\n",
    "\n",
    "for i in \"${!list[@]}\"; do\n",
    "    list_new[$i]=${list[$i]//,/}\n",
    "done\n",
    "\n",
    "# Printing the cleaned list\n",
    "for element in \"${list_new[@]}\"; do\n",
    "    echo \"$element\"\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: REGISTERED_dir=/home/marianne/prj/glioma_recurrence/glioma_recurrence/data/10/registered_1\n"
     ]
    }
   ],
   "source": [
    "%env REGISTERED_dir=$REGISTERED_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: EXAMS_LIST_STR='10_036'\n"
     ]
    }
   ],
   "source": [
    "# Get the sorted list of directories (exams) inside REGISTERED_dir\n",
    "exams_list = sorted([x for x in next(os.walk(REGISTERED_dir))[1]])\n",
    "\n",
    "# Convert the list to a string with each element inside single quotes and separated by a space\n",
    "exams_list_str = \" \".join([f\"'{x}'\" for x in exams_list])\n",
    "\n",
    "# Set it as an environment variable so Bash can access it\n",
    "%env EXAMS_LIST_STR=$exams_list_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## performing SynthSR and SynthSeg on CT1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGISTERED directory: /home/marianne/prj/glioma_recurrence/glioma_recurrence/data/10/registered_1\n",
      "PROCESSING SUBJECT FOLDER: 10_036\n",
      "Primary scan date: 20150101\n",
      "Running SynthSR on primary scan\n",
      "Using general model from January 2023 (version 2)\n",
      "/usr/local/freesurfer/models/synthsr_v20_230130.h5\n",
      "using 18 threads\n",
      "predicting 1/1\n",
      "Prediction without flipping\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "Prediction with flipping\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "\n",
      "prediction  saved in: /home/marianne/prj/glioma_recurrence/glioma_recurrence/data/10/registered_1/10_036/10_036_20150101_CT1_SynthSR.nii.gz\n",
      "\n",
      "If you use this tool in a publication, please cite:\n",
      "\n",
      "\n",
      "Joint super-resolution and synthesis of 1 mm isotropic MP-RAGE volumes from clinical \n",
      "MRI exams with scans of different orientation, resolution and contrast\n",
      "JE Iglesias, B Billot, Y Balbastre, A Tabari, J Conklin, RG Gonzalez, DC Alexander,\n",
      "P Golland, BL Edlow, B Fischl, for the ADNI\n",
      "NeuroImage, 118206 (2021)\n",
      "\n",
      "\n",
      "\n",
      "SynthSR: a public AI tool to turn heterogeneous clinical brain scans into \n",
      "high-resolution T1-weighted images for 3D morphometry\n",
      "JE Iglesias, B Billot, Y Balbastre, C Magdamo, S Arnold, S Das, B Edlow, D Alexander,\n",
      "P Golland, B Fischl\n",
      "Science Advances, 9(5), eadd3607 (2023)\n",
      "\n",
      "\n",
      "\n",
      "If you use the low-field (Hyperfine) version, please cite also:\n",
      "\n",
      "\n",
      "\n",
      "Quantitative Brain Morphometry of Portable Low-Field-Strength MRI Using \n",
      "Super-Resolution Machine Learning\n",
      "JE Iglesias, R Schleicher, S Laguna, B Billot, P Schaefer, B McKaig, JN Goldstein, \n",
      "KN Sheth, MS Rosen, WT Kimberly\n",
      "Radiology, 220522 (2022)\n",
      "\n",
      "\n",
      "\n",
      "Running SynthSeg on primary SynthSR output\n",
      "SynthSeg-robust 2.0\n",
      "using 19 threads\n",
      "predicting 1/1\n",
      "1/1 [==============================] - 22s 22s/step\n",
      "\n",
      "segmentation  saved in:    /home/marianne/prj/glioma_recurrence/glioma_recurrence/data/10/registered_1/10_036/10_036_20150101_CT1_SynthSR_synthseg_parc_robust.nii.gz\n",
      "volumes saved in:          /home/marianne/prj/glioma_recurrence/glioma_recurrence/data/10/registered_1/10_036/10_036_20150101_CT1_SynthSR_synthseg_parc_robust_vol.csv\n",
      "\n",
      "If you use this tool in a publication, please cite:\n",
      "SynthSeg: Segmentation of brain MRI scans of any contrast and resolution without retraining\n",
      "B. Billot, D.N. Greve, O. Puonti, A. Thielscher, K. Van Leemput, B. Fischl, A.V. Dalca, J.E. Iglesias\n",
      "Medical Image Analysis, accepted for publication.\n",
      "\n",
      "Robust machine learning segmentation for large-scale analysis of heterogeneous clinical brain MRI datasets\n",
      "B. Billot, C. Magdamo, Y. Cheng, S.E. Arnold, S. Das, J.E. Iglesias\n",
      "PNAS, accepted for publication.\n",
      "Processing recurrent scan from date: 20160529\n",
      "Running SynthSR on recurrent scan\n",
      "Using general model from January 2023 (version 2)\n",
      "/usr/local/freesurfer/models/synthsr_v20_230130.h5\n",
      "using 18 threads\n",
      "predicting 1/1\n",
      "Prediction without flipping\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Prediction with flipping\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "\n",
      "prediction  saved in: /home/marianne/prj/glioma_recurrence/glioma_recurrence/data/10/registered_1/10_036/10_036_20160529_CT1_SynthSR_registered_to_10_036_20150101.nii.gz\n",
      "\n",
      "If you use this tool in a publication, please cite:\n",
      "\n",
      "\n",
      "Joint super-resolution and synthesis of 1 mm isotropic MP-RAGE volumes from clinical \n",
      "MRI exams with scans of different orientation, resolution and contrast\n",
      "JE Iglesias, B Billot, Y Balbastre, A Tabari, J Conklin, RG Gonzalez, DC Alexander,\n",
      "P Golland, BL Edlow, B Fischl, for the ADNI\n",
      "NeuroImage, 118206 (2021)\n",
      "\n",
      "\n",
      "\n",
      "SynthSR: a public AI tool to turn heterogeneous clinical brain scans into \n",
      "high-resolution T1-weighted images for 3D morphometry\n",
      "JE Iglesias, B Billot, Y Balbastre, C Magdamo, S Arnold, S Das, B Edlow, D Alexander,\n",
      "P Golland, B Fischl\n",
      "Science Advances, 9(5), eadd3607 (2023)\n",
      "\n",
      "\n",
      "\n",
      "If you use the low-field (Hyperfine) version, please cite also:\n",
      "\n",
      "\n",
      "\n",
      "Quantitative Brain Morphometry of Portable Low-Field-Strength MRI Using \n",
      "Super-Resolution Machine Learning\n",
      "JE Iglesias, R Schleicher, S Laguna, B Billot, P Schaefer, B McKaig, JN Goldstein, \n",
      "KN Sheth, MS Rosen, WT Kimberly\n",
      "Radiology, 220522 (2022)\n",
      "\n",
      "\n",
      "\n",
      "Running SynthSeg on recurrent SynthSR output\n",
      "SynthSeg-robust 2.0\n",
      "using 19 threads\n",
      "predicting 1/1\n",
      "1/1 [==============================] - 23s 23s/step\n",
      "\n",
      "segmentation  saved in:    /home/marianne/prj/glioma_recurrence/glioma_recurrence/data/10/registered_1/10_036/10_036_20160529_CT1_SynthSR_synthseg_parc_robust_registered_to_10_036_20150101.nii.gz\n",
      "volumes saved in:          /home/marianne/prj/glioma_recurrence/glioma_recurrence/data/10/registered_1/10_036/10_036_20160529_CT1_SynthSR_synthseg_parc_robust_registered_to_10_036_20150101_vol.csv\n",
      "\n",
      "If you use this tool in a publication, please cite:\n",
      "SynthSeg: Segmentation of brain MRI scans of any contrast and resolution without retraining\n",
      "B. Billot, D.N. Greve, O. Puonti, A. Thielscher, K. Van Leemput, B. Fischl, A.V. Dalca, J.E. Iglesias\n",
      "Medical Image Analysis, accepted for publication.\n",
      "\n",
      "Robust machine learning segmentation for large-scale analysis of heterogeneous clinical brain MRI datasets\n",
      "B. Billot, C. Magdamo, Y. Cheng, S.E. Arnold, S. Das, J.E. Iglesias\n",
      "PNAS, accepted for publication.\n",
      "Completed processing for 10_036\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$REGISTERED_dir\"\n",
    "\n",
    "echo \"REGISTERED directory: $1\"\n",
    "\n",
    "# Set up environment\n",
    "FREESURFER_HOME=/usr/local/freesurfer/; export FREESURFER_HOME\n",
    "PATH=${FREESURFER_HOME}/bin:${PATH}; export PATH\n",
    "FSLDIR=/usr/local/fsl; export FSLDIR\n",
    "PATH=${FSLDIR}/bin:${PATH}; export PATH\n",
    ". ${FSLDIR}/etc/fslconf/fsl.sh\n",
    "source ${FREESURFER_HOME}/SetUpFreeSurfer.sh\n",
    "\n",
    "# Convert the space-separated string of quoted elements into an array\n",
    "IFS=' ' read -r -a list_new <<< \"$EXAMS_LIST_STR\"\n",
    "\n",
    "# Process each subject folder\n",
    "for subject_folder in \"${list_new[@]}\"; do\n",
    "    # Remove any surrounding single quotes from the folder name\n",
    "    subject_folder=${subject_folder//\\'/}\n",
    "    echo \"PROCESSING SUBJECT FOLDER: $subject_folder\"\n",
    "    \n",
    "    # Find the primary scan date by looking at the CT1 file pattern\n",
    "    primary_scan=$(find \"$1/$subject_folder\" -maxdepth 1 -type f -name \"${subject_folder}_*_CT1_coreg.nii.gz\" | head -n 1)\n",
    "    \n",
    "    if [ -z \"$primary_scan\" ]; then\n",
    "        echo \"ERROR: No CT1 scan found for $subject_folder\"\n",
    "        continue\n",
    "    fi\n",
    "    \n",
    "    # Extract the primary date from the filename\n",
    "    primary_date=$(basename \"$primary_scan\" | cut -d'_' -f3)\n",
    "    echo \"Primary scan date: $primary_date\"\n",
    "    \n",
    "    # Process primary scan\n",
    "    primary_CT1=\"${1}/${subject_folder}/${subject_folder}_${primary_date}_CT1_coreg.nii.gz\"\n",
    "    \n",
    "    if [ ! -f \"$primary_CT1\" ]; then\n",
    "        echo \"ERROR: CT1 not available for primary scan\"\n",
    "        continue\n",
    "    fi\n",
    "    \n",
    "    # Process primary scan with SynthSR\n",
    "    echo \"Running SynthSR on primary scan\"\n",
    "    mri_synthsr \\\n",
    "        --i \"$primary_CT1\" \\\n",
    "        --o \"${1}/${subject_folder}/${subject_folder}_${primary_date}_CT1_SynthSR.nii.gz\" \\\n",
    "        --threads 18\n",
    "        \n",
    "    # Run SynthSeg on primary SynthSR output\n",
    "    if [ -f \"${1}/${subject_folder}/${subject_folder}_${primary_date}_CT1_SynthSR.nii.gz\" ]; then\n",
    "        echo \"Running SynthSeg on primary SynthSR output\"\n",
    "        mri_synthseg \\\n",
    "            --i \"${1}/${subject_folder}/${subject_folder}_${primary_date}_CT1_SynthSR.nii.gz\" \\\n",
    "            --o \"${1}/${subject_folder}/${subject_folder}_${primary_date}_CT1_SynthSR_synthseg_parc_robust.nii.gz\" \\\n",
    "            --vol \"${1}/${subject_folder}/${subject_folder}_${primary_date}_CT1_SynthSR_synthseg_parc_robust_vol.csv\" \\\n",
    "            --parc \\\n",
    "            --robust \\\n",
    "            --threads 19\n",
    "    fi\n",
    "    \n",
    "    # Find and process recurrent scan\n",
    "    recurrent_CT1_path=$(find \"$1/$subject_folder\" -maxdepth 1 -type f -name \"${subject_folder}_*_CT1_coreg_registered_to_${subject_folder}_${primary_date}.nii.gz\" | head -n 1)\n",
    "    \n",
    "    if [ -n \"$recurrent_CT1_path\" ]; then\n",
    "        # Extract recurrent date from filename\n",
    "        recurrent_date=$(basename \"$recurrent_CT1_path\" | cut -d'_' -f3)\n",
    "        echo \"Processing recurrent scan from date: $recurrent_date\"\n",
    "        \n",
    "        # Process recurrent scan with SynthSR\n",
    "        echo \"Running SynthSR on recurrent scan\"\n",
    "        mri_synthsr \\\n",
    "            --i \"$recurrent_CT1_path\" \\\n",
    "            --o \"${1}/${subject_folder}/${subject_folder}_${recurrent_date}_CT1_SynthSR_registered_to_${subject_folder}_${primary_date}.nii.gz\" \\\n",
    "            --threads 18\n",
    "            \n",
    "        # Run SynthSeg on recurrent SynthSR output\n",
    "        if [ -f \"${1}/${subject_folder}/${subject_folder}_${recurrent_date}_CT1_SynthSR_registered_to_${subject_folder}_${primary_date}.nii.gz\" ]; then\n",
    "            echo \"Running SynthSeg on recurrent SynthSR output\"\n",
    "            mri_synthseg \\\n",
    "                --i \"${1}/${subject_folder}/${subject_folder}_${recurrent_date}_CT1_SynthSR_registered_to_${subject_folder}_${primary_date}.nii.gz\" \\\n",
    "                --o \"${1}/${subject_folder}/${subject_folder}_${recurrent_date}_CT1_SynthSR_synthseg_parc_robust_registered_to_${subject_folder}_${primary_date}.nii.gz\" \\\n",
    "                --vol \"${1}/${subject_folder}/${subject_folder}_${recurrent_date}_CT1_SynthSR_synthseg_parc_robust_registered_to_${subject_folder}_${primary_date}_vol.csv\" \\\n",
    "                --parc \\\n",
    "                --robust \\\n",
    "                --threads 19\n",
    "        fi\n",
    "    else\n",
    "        echo \"No recurrent CT1 scan found for $subject_folder\"\n",
    "    fi\n",
    "    \n",
    "    echo \"Completed processing for $subject_folder\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing synthetic white-matter lobes based on KNN (K=3) of synthseg-derived hemispheric white matter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subjects: ['10_036']\n",
      "Processing 1 subjects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing subject: 10_036\n",
      "Processing primary scan: 10_036_20150101_CT1_SynthSR_synthseg_parc_robust.nii.gz\n",
      "Processing /home/marianne/prj/glioma_recurrence/glioma_recurrence/data/10/registered_1/10_036/10_036_20150101_CT1_SynthSR_synthseg_parc_robust.nii.gz\n",
      "Processing left hemisphere\n",
      "Found 272608 white matter voxels\n",
      "Found 294614 training points\n",
      "Training KNN classifier\n",
      "Predicting labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "left hemisphere progress: 100%|██████████| 3/3 [00:00<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing right hemisphere\n",
      "Found 247298 white matter voxels\n",
      "Found 290607 training points\n",
      "Training KNN classifier\n",
      "Predicting labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "right hemisphere progress: 100%|██████████| 3/3 [00:00<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving output to /home/marianne/prj/glioma_recurrence/glioma_recurrence/data/10/registered_1/10_036/10_036_20150101_CT1_SR_synthetic_wm_lobes.nii.gz\n",
      "Processing complete\n",
      "Processing recurrent scan: 10_036_20160529_CT1_SynthSR_synthseg_parc_robust_registered_to_10_036_20150101.nii.gz\n",
      "Processing /home/marianne/prj/glioma_recurrence/glioma_recurrence/data/10/registered_1/10_036/10_036_20160529_CT1_SynthSR_synthseg_parc_robust_registered_to_10_036_20150101.nii.gz\n",
      "Processing left hemisphere\n",
      "Found 256022 white matter voxels\n",
      "Found 282547 training points\n",
      "Training KNN classifier\n",
      "Predicting labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "left hemisphere progress: 100%|██████████| 3/3 [00:00<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing right hemisphere\n",
      "Found 251015 white matter voxels\n",
      "Found 292444 training points\n",
      "Training KNN classifier\n",
      "Predicting labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "right hemisphere progress: 100%|██████████| 3/3 [00:00<00:00,  3.51it/s]\n",
      "Overall progress: 100%|██████████| 1/1 [00:05<00:00,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving output to /home/marianne/prj/glioma_recurrence/glioma_recurrence/data/10/registered_1/10_036/10_036_20160529_CT1_SR_synthetic_wm_lobes_registered_to_10_036_20150101.nii.gz\n",
      "Processing complete\n",
      "All processing complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get the subject list from environment variable and clean it\n",
    "subject_list_str = os.environ['EXAMS_LIST_STR']\n",
    "subject_list = [s.strip(\"'\") for s in subject_list_str.split()]\n",
    "\n",
    "print(\"Processing subjects:\", subject_list)  # For verification\n",
    "\n",
    "LOBE_MAPPING = {\n",
    "    # Left hemisphere cortical lobes\n",
    "    'left_frontal': [\n",
    "        1002,  # ctx-lh-caudalanteriorcingulate\n",
    "        1003,  # ctx-lh-caudalmiddlefrontal\n",
    "        1012,  # ctx-lh-lateralorbitofrontal\n",
    "        1014,  # ctx-lh-medialorbitofrontal\n",
    "        1018,  # ctx-lh-parsopercularis\n",
    "        1019,  # ctx-lh-parsorbitalis\n",
    "        1020,  # ctx-lh-parstriangularis\n",
    "        1024,  # ctx-lh-precentral\n",
    "        1026,  # ctx-lh-rostralanteriorcingulate\n",
    "        1027,  # ctx-lh-rostralmiddlefrontal\n",
    "        1028,  # ctx-lh-superiorfrontal\n",
    "        1032   # ctx-lh-frontalpole\n",
    "    ],\n",
    "\n",
    "    'left_parietal': [\n",
    "        1008,  # ctx-lh-inferiorparietal\n",
    "        1022,  # ctx-lh-postcentral\n",
    "        1025,  # ctx-lh-precuneus\n",
    "        1029,  # ctx-lh-superiorparietal\n",
    "        1031,  # ctx-lh-supramarginal\n",
    "        1010   # ctx-lh-isthmuscingulate\n",
    "    ],\n",
    "\n",
    "    'left_temporal': [\n",
    "        1001,  # ctx-lh-bankssts\n",
    "        1006,  # ctx-lh-entorhinal\n",
    "        1007,  # ctx-lh-fusiform\n",
    "        1009,  # ctx-lh-inferiortemporal\n",
    "        1015,  # ctx-lh-middletemporal\n",
    "        1016,  # ctx-lh-parahippocampal\n",
    "        1030,  # ctx-lh-superiortemporal\n",
    "        1033,  # ctx-lh-temporalpole\n",
    "        1034,  # ctx-lh-transversetemporal\n",
    "        17,    # Left-Hippocampus\n",
    "        18     # Left-Amygdala\n",
    "    ],\n",
    "\n",
    "    'left_occipital': [\n",
    "        1005,  # ctx-lh-cuneus\n",
    "        1011,  # ctx-lh-lateraloccipital\n",
    "        1013,  # ctx-lh-lingual\n",
    "        1021   # ctx-lh-pericalcarine\n",
    "    ],\n",
    "\n",
    "    # Right hemisphere cortical lobes\n",
    "    'right_frontal': [\n",
    "        2002,  # ctx-rh-caudalanteriorcingulate\n",
    "        2003,  # ctx-rh-caudalmiddlefrontal\n",
    "        2012,  # ctx-rh-lateralorbitofrontal\n",
    "        2014,  # ctx-rh-medialorbitofrontal\n",
    "        2018,  # ctx-rh-parsopercularis\n",
    "        2019,  # ctx-rh-parsorbitalis\n",
    "        2020,  # ctx-rh-parstriangularis\n",
    "        2024,  # ctx-rh-precentral\n",
    "        2026,  # ctx-rh-rostralanteriorcingulate\n",
    "        2027,  # ctx-rh-rostralmiddlefrontal\n",
    "        2028,  # ctx-rh-superiorfrontal\n",
    "        2032   # ctx-rh-frontalpole\n",
    "    ],\n",
    "\n",
    "    'right_parietal': [\n",
    "        2008,  # ctx-rh-inferiorparietal\n",
    "        2022,  # ctx-rh-postcentral\n",
    "        2025,  # ctx-rh-precuneus\n",
    "        2029,  # ctx-rh-superiorparietal\n",
    "        2031,  # ctx-rh-supramarginal\n",
    "        2010   # ctx-rh-isthmuscingulate\n",
    "    ],\n",
    "\n",
    "    'right_temporal': [\n",
    "        2001,  # ctx-rh-bankssts\n",
    "        2006,  # ctx-rh-entorhinal\n",
    "        2007,  # ctx-rh-fusiform\n",
    "        2009,  # ctx-rh-inferiortemporal\n",
    "        2015,  # ctx-rh-middletemporal\n",
    "        2016,  # ctx-rh-parahippocampal\n",
    "        2030,  # ctx-rh-superiortemporal\n",
    "        2033,  # ctx-rh-temporalpole\n",
    "        2034,  # ctx-rh-transversetemporal\n",
    "        53,    # Right-Hippocampus\n",
    "        54     # Right-Amygdala\n",
    "    ],\n",
    "\n",
    "    'right_occipital': [\n",
    "        2005,  # ctx-rh-cuneus\n",
    "        2011,  # ctx-rh-lateraloccipital\n",
    "        2013,  # ctx-rh-lingual\n",
    "        2021   # ctx-rh-pericalcarine\n",
    "    ],\n",
    "\n",
    "    # Non-lobular regions\n",
    "    'brainstem': [16],  # Brain-Stem\n",
    "    'corpus_callosum': [\n",
    "        251,  # CC_Posterior\n",
    "        252,  # CC_Mid_Posterior\n",
    "        253,  # CC_Central\n",
    "        254,  # CC_Mid_Anterior\n",
    "        255   # CC_Anterior\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "# Define output labels for lobes - using values in the 900s range to avoid conflicts\n",
    "LOBE_LABELS = {\n",
    "    'left_frontal': 3201,\n",
    "    'left_parietal': 3206,\n",
    "    'left_temporal': 3205,\n",
    "    'left_occipital': 3204,\n",
    "    'right_frontal': 4201,\n",
    "    'right_parietal': 4206,\n",
    "    'right_temporal': 4205,\n",
    "    'right_occipital': 4204\n",
    "}\n",
    "\n",
    "def get_voxel_coordinates(mask):\n",
    "    \"\"\"Get coordinates of all non-zero voxels in the mask.\"\"\"\n",
    "    return np.array(np.where(mask)).T\n",
    "\n",
    "def process_voxel(args):\n",
    "    \"\"\"Process a single voxel for white matter segmentation with fixed K=3.\"\"\"\n",
    "    wm_coord, train_coords, train_labels = args\n",
    "    # Find nearest neighbors\n",
    "    dists = np.sqrt(np.sum((train_coords - wm_coord)**2, axis=1))\n",
    "    \n",
    "    # Get 3 nearest neighbors\n",
    "    nearest_indices = np.argsort(dists)[:3]  # Fixed K=3\n",
    "    nearest_labels = train_labels[nearest_indices]\n",
    "    nearest_dists = dists[nearest_indices]\n",
    "    \n",
    "    # Weight by inverse distance\n",
    "    weights = 1 / (nearest_dists + 1e-6)\n",
    "    weights /= weights.sum()\n",
    "    \n",
    "    # Weighted vote\n",
    "    label_votes = defaultdict(float)\n",
    "    for label, weight in zip(nearest_labels, weights):\n",
    "        label_votes[label] += weight\n",
    "    \n",
    "    # Get label with highest weighted vote\n",
    "    predicted_label = max(label_votes.items(), key=lambda x: x[1])[0]\n",
    "    return predicted_label\n",
    "\n",
    "def segment_wm_lobes(input_path, output_path, n_jobs=20):\n",
    "    \"\"\"Segment white matter into lobes using vectorized KNN.\"\"\"\n",
    "    print(f\"Processing {input_path}\")\n",
    "    \n",
    "    # Load the SynthSeg parcellation\n",
    "    img = nib.load(input_path)\n",
    "    data = img.get_fdata()\n",
    "    \n",
    "    # Create output array\n",
    "    output = np.zeros_like(data)\n",
    "    \n",
    "    # Process each hemisphere separately\n",
    "    for hemi in ['left', 'right']:\n",
    "        print(f\"Processing {hemi} hemisphere\")\n",
    "        # Get WM mask for this hemisphere\n",
    "        wm_label = 2 if hemi == 'left' else 41\n",
    "        wm_mask = data == wm_label\n",
    "        \n",
    "        if not np.any(wm_mask):\n",
    "            continue\n",
    "        \n",
    "        # Get coordinates of WM voxels\n",
    "        wm_coords = get_voxel_coordinates(wm_mask)\n",
    "        print(f\"Found {len(wm_coords)} white matter voxels\")\n",
    "        \n",
    "        # Prepare training data from cortical regions\n",
    "        train_coords = []\n",
    "        train_labels = []\n",
    "        \n",
    "        for lobe, label in LOBE_LABELS.items():\n",
    "            if lobe.startswith(hemi):\n",
    "                lobe_mask = np.zeros_like(data, dtype=bool)\n",
    "                for region in LOBE_MAPPING[lobe]:\n",
    "                    lobe_mask |= (data == region)\n",
    "                \n",
    "                if np.any(lobe_mask):\n",
    "                    coords = get_voxel_coordinates(lobe_mask)\n",
    "                    train_coords.extend(coords)\n",
    "                    train_labels.extend([label] * len(coords))\n",
    "        \n",
    "        if train_coords:\n",
    "            print(f\"Found {len(train_coords)} training points\")\n",
    "            train_coords = np.array(train_coords)\n",
    "            train_labels = np.array(train_labels)\n",
    "            \n",
    "            # Use scikit-learn's KNN directly - much faster than manual implementation\n",
    "            print(\"Training KNN classifier\")\n",
    "            knn = KNeighborsClassifier(n_neighbors=3, weights='distance', n_jobs=n_jobs)\n",
    "            knn.fit(train_coords, train_labels)\n",
    "            \n",
    "            # Predict in batches to avoid memory issues\n",
    "            batch_size = 100000  # Adjust based on available memory\n",
    "            n_batches = (len(wm_coords) + batch_size - 1) // batch_size\n",
    "            \n",
    "            print(\"Predicting labels\")\n",
    "            for i in tqdm(range(n_batches), desc=f\"{hemi} hemisphere progress\"):\n",
    "                start_idx = i * batch_size\n",
    "                end_idx = min((i + 1) * batch_size, len(wm_coords))\n",
    "                batch_coords = wm_coords[start_idx:end_idx]\n",
    "                \n",
    "                # Predict for batch\n",
    "                batch_predictions = knn.predict(batch_coords)\n",
    "                \n",
    "                # Assign predictions to output\n",
    "                for coord, label in zip(batch_coords, batch_predictions):\n",
    "                    output[tuple(coord)] = label\n",
    "    \n",
    "    # Save the result\n",
    "    print(f\"Saving output to {output_path}\")\n",
    "    nib_out = nib.Nifti1Image(output, img.affine, img.header)\n",
    "    nib.save(nib_out, output_path)\n",
    "    print(\"Processing complete\")\n",
    "\n",
    "def process_subject(args):\n",
    "    \"\"\"Process a single subject\"\"\"\n",
    "    registered_dir, subject = args\n",
    "    print(f\"\\nProcessing subject: {subject}\")\n",
    "    \n",
    "    # Find primary and recurrent scans\n",
    "    subject_dir = os.path.join(registered_dir, subject)\n",
    "    \n",
    "    primary_scan = None\n",
    "    recurrent_scan = None\n",
    "    \n",
    "    # Updated file pattern matching for CT1\n",
    "    for file in os.listdir(subject_dir):\n",
    "        if file.endswith('.nii.gz'):\n",
    "            if '_CT1_SynthSR_synthseg_parc_robust.nii.gz' in file and 'registered_to' not in file:\n",
    "                primary_scan = file\n",
    "            elif '_CT1_SynthSR_synthseg_parc_robust_registered_to' in file and subject in file:\n",
    "                recurrent_scan = file\n",
    "    \n",
    "    if primary_scan:\n",
    "        print(f\"Processing primary scan: {primary_scan}\")\n",
    "        input_path = os.path.join(subject_dir, primary_scan)\n",
    "        output_path = os.path.join(subject_dir, \n",
    "            primary_scan.replace('_CT1_SynthSR_synthseg_parc_robust.nii.gz', \n",
    "                               '_CT1_SR_synthetic_wm_lobes.nii.gz'))\n",
    "        segment_wm_lobes(input_path, output_path, n_jobs=20)\n",
    "    else:\n",
    "        print(f\"No primary CT1 scan found for subject {subject}\")\n",
    "\n",
    "    if recurrent_scan:\n",
    "        print(f\"Processing recurrent scan: {recurrent_scan}\")\n",
    "        input_path = os.path.join(subject_dir, recurrent_scan)\n",
    "        output_path = os.path.join(subject_dir,\n",
    "            recurrent_scan.replace('_CT1_SynthSR_synthseg_parc_robust_registered_to',\n",
    "                                 '_CT1_SR_synthetic_wm_lobes_registered_to'))\n",
    "        segment_wm_lobes(input_path, output_path, n_jobs=20)\n",
    "    else:\n",
    "        print(f\"No recurrent CT1 scan found for subject {subject}\")\n",
    "\n",
    "def process_all_subjects(registered_dir, subject_list):\n",
    "    \"\"\"Process all subjects with progress bar\"\"\"\n",
    "    print(f\"Processing {len(subject_list)} subjects\")\n",
    "    \n",
    "    for subject in tqdm(subject_list, desc=\"Overall progress\", position=0):\n",
    "        process_subject((registered_dir, subject))\n",
    "\n",
    "# Execute the processing (either for one subject or all)\n",
    "registered_dir = os.environ['REGISTERED_dir']\n",
    "\n",
    "# For all subjects:\n",
    "process_all_subjects(registered_dir, subject_list)\n",
    "print(\"All processing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
